---
title: "TF-IDF and n-grams"
output: html_notebook
---

```{r}
library(tidytext)
library(tidyverse)
library(janeaustenr)
```

gutenberg.org

## TF-IDF

Trem Frequency - Inverse Document Frequency

```{r}
sentences <- c(
  "This is a sentence about cats.",
  "This is a sentence about dogs.",
  "This is a sentence about alligators."
)
```

```{r}
sentences_df <- tibble(
  sentence = sentences,
  id = 1:3
) %>%
unnest_tokens(word, sentence) 

sentences_df
```

```{r}
sentences_df %>% 
  count(word, id) %>%
  bind_tf_idf(term = word, 
              document = id, n = n)
```

__TF:__ Term Frequency
Will be high for important words (in a document)

__DF:__
Will be low if it is in a few documents

__IDF:__ Inverse Document Frequency
log(1 / DF)

__TF-IDF:__ Term Frequency - Inverse Document Frequency
Is a measure of how important a word is to document in a collection of documents


document can be a twitter, a book, a sentence 


$$TF = \frac{\textrm{How often term appears in document}}{\textrm{Number of terms in document}}$$

$$
DF = \frac{\text{Number of documents term appears in}}{\text{Number of documents}}
$$

$$
TF-IDF = TF \times log(\frac{1}{DF})
$$


```{r}
titles <- c("Pride and Prejudice", "Sense and Sensibility", 
            "Emma", "Persuasion", "Mansfield Park", "Northanger Abbey")

books <- list(prideprejudice, sensesensibility, 
              emma, persuasion, mansfieldpark,  northangerabbey)

```

```{r}
books <- purrr::map_chr(books, paste, collapse = " ")
```

```{r}
head(prideprejudice, 20)
```

```{r}
str(books)
```

```{r}
object.size(books)
```

```{r}
all_books_df <- tibble(
  title = titles,
  text = books
) %>%
  unnest_tokens(word, text)

head(all_books_df)
```

```{r}
all_books_tf_idf <- all_books_df %>% 
  count(word, title) %>% 
  bind_tf_idf(word, title, n) %>% 
  arrange(desc(tf_idf))

all_books_tf_idf
```

```{r}
all_books_tf_idf %>%
  group_by(title) %>%
  slice_max(tf_idf)
```

## N-grams

```{r}
phrases <- c(
  "here is some text",
  "again more text",
  "text is text"
)

phrases_df <- tibble(
  phrase = phrases,
  id     = 1:3
) 

phrases_df %>%
  unnest_tokens(bigram, 
                phrase, token = "ngrams", n = 2)
```

```{r}
book_df <- tibble(
  id = 1:length(prideprejudice),
  text = prideprejudice
) 

book_df %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>% 
  count(bigram, sort = TRUE)

book_df %>% 
  unnest_tokens(trigram, text, token = "ngrams", n = 3) %>% 
  count(trigram, sort = TRUE)

book_df %>% 
  unnest_tokens(character, text, token = "characters") %>% 
  count(character, sort = TRUE)

```

## separate()

```{r}
book_bigrams <- book_df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  separate(bigram, c("word_1", "word_2"), sep = " ") %>%
  anti_join(stop_words, by = c("word_1" = "word")) %>%
  anti_join(stop_words, by = c("word_2" = "word")) 

book_bigrams
```

```{r}
book_bigrams %>% 
  unite(bigram, word_1, word_2, remove = FALSE, sep = " ")
```


```{r}
tibble(word = emma) %>% 
  unnest_tokens(ngram, word, token = "ngrams", n = 2) %>% 
  count(ngram, sort = T) %>% 
  separate(ngram, c("w1", "w2"), sep = " ") %>% 
  anti_join(stop_words, by = c("w1" = "word")) %>% 
  anti_join(stop_words, by = c("w2" = "word")) %>%
  unite(bigram, w1, w2, remove = F, sep = " ")
```




